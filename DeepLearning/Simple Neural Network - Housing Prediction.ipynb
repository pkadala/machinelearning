{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0      5650     1.0           0     0  ...      7        1180              0   \n",
       "1      7242     2.0           0     0  ...      7        2170            400   \n",
       "2     10000     1.0           0     0  ...      6         770              0   \n",
       "3      5000     1.0           0     0  ...      7        1050            910   \n",
       "4      8080     1.0           0     0  ...      8        1680              0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1955             0    98178  47.5112 -122.257           1340   \n",
       "1      1951          1991    98125  47.7210 -122.319           1690   \n",
       "2      1933             0    98028  47.7379 -122.233           2720   \n",
       "3      1965             0    98136  47.5208 -122.393           1360   \n",
       "4      1987             0    98074  47.6168 -122.045           1800   \n",
       "\n",
       "   sqft_lot15  \n",
       "0        5650  \n",
       "1        7639  \n",
       "2        8062  \n",
       "3        5000  \n",
       "4        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('kc_house_data.csv')\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21613 entries, 0 to 21612\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             21613 non-null  int64  \n",
      " 1   date           21613 non-null  object \n",
      " 2   price          21613 non-null  float64\n",
      " 3   bedrooms       21613 non-null  int64  \n",
      " 4   bathrooms      21613 non-null  float64\n",
      " 5   sqft_living    21613 non-null  int64  \n",
      " 6   sqft_lot       21613 non-null  int64  \n",
      " 7   floors         21613 non-null  float64\n",
      " 8   waterfront     21613 non-null  int64  \n",
      " 9   view           21613 non-null  int64  \n",
      " 10  condition      21613 non-null  int64  \n",
      " 11  grade          21613 non-null  int64  \n",
      " 12  sqft_above     21613 non-null  int64  \n",
      " 13  sqft_basement  21613 non-null  int64  \n",
      " 14  yr_built       21613 non-null  int64  \n",
      " 15  yr_renovated   21613 non-null  int64  \n",
      " 16  zipcode        21613 non-null  int64  \n",
      " 17  lat            21613 non-null  float64\n",
      " 18  long           21613 non-null  float64\n",
      " 19  sqft_living15  21613 non-null  int64  \n",
      " 20  sqft_lot15     21613 non-null  int64  \n",
      "dtypes: float64(5), int64(15), object(1)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = dataset.drop('date',axis=1)\n",
    "dataset = dataset.drop('id',axis=1)\n",
    "dataset = dataset.drop('zipcode',axis=1)\n",
    "\n",
    "X = dataset.drop('price',axis =1).values\n",
    "y = dataset['price'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (14480, 17)\n",
      "y_train (14480,)\n",
      "X_test (7133, 17)\n",
      "y_test (7133,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train', X_train.shape)\n",
    "print('y_train', y_train.shape)\n",
    "print('X_test', X_test.shape)\n",
    "print('y_test', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train.astype(np.float))\n",
    "X_test = scaler.transform(X_test.astype(np.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def print_evaluate(true, predicted):  \n",
    "    mae = metrics.mean_absolute_error(true, predicted)\n",
    "    mse = metrics.mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n",
    "    r2_square = metrics.r2_score(true, predicted)\n",
    "    print('MAE:', mae)\n",
    "    print('MSE:', mse)\n",
    "    print('RMSE:', rmse)\n",
    "    print('R2 Square', r2_square)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 126461.4233793007\n",
      "MSE: 40832399808.40884\n",
      "RMSE: 202070.28432802492\n",
      "R2 Square 0.7022743439606974\n"
     ]
    }
   ],
   "source": [
    "# Multiple Liner Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()  \n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "print_evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 419021351642.7841 - val_loss: 414290804736.0000\n",
      "Epoch 2/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 396218397087.0132 - val_loss: 325365563392.0000\n",
      "Epoch 3/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 302402047440.6343 - val_loss: 189072621568.0000\n",
      "Epoch 4/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 169948820628.8634 - val_loss: 101438578688.0000\n",
      "Epoch 5/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 100421421858.9604 - val_loss: 74253344768.0000\n",
      "Epoch 6/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 78968003579.4890 - val_loss: 66536263680.0000\n",
      "Epoch 7/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 67942466357.0044 - val_loss: 62483259392.0000\n",
      "Epoch 8/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 65365374258.7489 - val_loss: 59444097024.0000\n",
      "Epoch 9/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 61594865294.0969 - val_loss: 56795652096.0000\n",
      "Epoch 10/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 58696116233.0220 - val_loss: 54338199552.0000\n",
      "Epoch 11/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 58426481916.6167 - val_loss: 52015095808.0000\n",
      "Epoch 12/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 52183163592.7401 - val_loss: 49758011392.0000\n",
      "Epoch 13/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 50752872204.4053 - val_loss: 47626878976.0000\n",
      "Epoch 14/75\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 49374800377.2335 - val_loss: 45637906432.0000\n",
      "Epoch 15/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 45327191671.5418 - val_loss: 43844329472.0000\n",
      "Epoch 16/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 43514998540.4053 - val_loss: 42178859008.0000\n",
      "Epoch 17/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 43104453501.1806 - val_loss: 40634294272.0000\n",
      "Epoch 18/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 43474788392.5991 - val_loss: 39366144000.0000\n",
      "Epoch 19/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 44256219090.8899 - val_loss: 38330650624.0000\n",
      "Epoch 20/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 36965481756.1938 - val_loss: 37492826112.0000\n",
      "Epoch 21/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 40592749288.3172 - val_loss: 36805906432.0000\n",
      "Epoch 22/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 36410817978.0793 - val_loss: 36249358336.0000\n",
      "Epoch 23/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 37523501371.7709 - val_loss: 35833864192.0000\n",
      "Epoch 24/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 37404658974.4493 - val_loss: 35481133056.0000\n",
      "Epoch 25/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 35665383453.3216 - val_loss: 35188006912.0000\n",
      "Epoch 26/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 37210614080.2819 - val_loss: 34958614528.0000\n",
      "Epoch 27/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 37224422589.4626 - val_loss: 34737696768.0000\n",
      "Epoch 28/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 36799724945.4802 - val_loss: 34543046656.0000\n",
      "Epoch 29/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 36687414136.6696 - val_loss: 34384683008.0000\n",
      "Epoch 30/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 34128175076.9339 - val_loss: 34301859840.0000\n",
      "Epoch 31/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 35900905129.1630 - val_loss: 34089197568.0000\n",
      "Epoch 32/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 38060393941.1454 - val_loss: 34007269376.0000\n",
      "Epoch 33/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 34370168051.5947 - val_loss: 33857671168.0000\n",
      "Epoch 34/75\n",
      "453/453 [==============================] - 2s 5ms/step - loss: 34426412068.0881 - val_loss: 33741592576.0000\n",
      "Epoch 35/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 35131218082.3965 - val_loss: 33634467840.0000\n",
      "Epoch 36/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 34071779188.1586 - val_loss: 33538277376.0000\n",
      "Epoch 37/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 32964047678.0264 - val_loss: 33460355072.0000\n",
      "Epoch 38/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 33188997291.4185 - val_loss: 33348073472.0000\n",
      "Epoch 39/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 33690525856.1410 - val_loss: 33266432000.0000\n",
      "Epoch 40/75\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 35361971628.5463 - val_loss: 33186889728.0000\n",
      "Epoch 41/75\n",
      "453/453 [==============================] - 2s 5ms/step - loss: 34807746226.1850 - val_loss: 33118310400.0000\n",
      "Epoch 42/75\n",
      "453/453 [==============================] - 2s 5ms/step - loss: 32744895192.5286 - val_loss: 33055076352.0000\n",
      "Epoch 43/75\n",
      "453/453 [==============================] - 2s 5ms/step - loss: 34571202650.2203 - val_loss: 32981600256.0000\n",
      "Epoch 44/75\n",
      "453/453 [==============================] - 2s 3ms/step - loss: 31191988309.7093 - val_loss: 32944115712.0000\n",
      "Epoch 45/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 36175611407.7885 - val_loss: 32885762048.0000\n",
      "Epoch 46/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 33787396181.7093 - val_loss: 32832305152.0000\n",
      "Epoch 47/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 36000745629.8855 - val_loss: 32777449472.0000\n",
      "Epoch 48/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 31909619951.0837 - val_loss: 32744003584.0000\n",
      "Epoch 49/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 36150636602.6432 - val_loss: 32680275968.0000\n",
      "Epoch 50/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 31548713988.5110 - val_loss: 32631525376.0000\n",
      "Epoch 51/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 35213669759.4361 - val_loss: 32597886976.0000\n",
      "Epoch 52/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 33156996944.0705 - val_loss: 32571973632.0000\n",
      "Epoch 53/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 32691691222.2731 - val_loss: 32502487040.0000\n",
      "Epoch 54/75\n",
      "453/453 [==============================] - 2s 4ms/step - loss: 31265700214.4141 - val_loss: 32499302400.0000\n",
      "Epoch 55/75\n",
      "453/453 [==============================] - 2s 5ms/step - loss: 32993389568.0000 - val_loss: 32430131200.0000\n",
      "Epoch 56/75\n",
      "453/453 [==============================] - 2s 5ms/step - loss: 33838562191.2247 - val_loss: 32391667712.0000\n",
      "Epoch 57/75\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 35051278081.1278 - val_loss: 32355299328.0000\n",
      "Epoch 58/75\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 31378601790.0264 - val_loss: 32325888000.0000\n",
      "Epoch 59/75\n",
      "453/453 [==============================] - 1s 3ms/step - loss: 34021462264.1057 - val_loss: 32284846080.0000\n",
      "Epoch 60/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 32819046695.4714 - val_loss: 32264361984.0000\n",
      "Epoch 61/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 33264632723.7357 - val_loss: 32217223168.0000\n",
      "Epoch 62/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 30871759308.1233 - val_loss: 32295682048.0000\n",
      "Epoch 63/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 33435438851.3833 - val_loss: 32159207424.0000\n",
      "Epoch 64/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 30712395442.1850 - val_loss: 32123045888.0000\n",
      "Epoch 65/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 35583775536.4934 - val_loss: 32083077120.0000\n",
      "Epoch 66/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 32594874584.5286 - val_loss: 32074463232.0000\n",
      "Epoch 67/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 32586828743.6123 - val_loss: 32018653184.0000\n",
      "Epoch 68/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 30323932944.9163 - val_loss: 32020547584.0000\n",
      "Epoch 69/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 32971296537.9383 - val_loss: 31967975424.0000\n",
      "Epoch 70/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 35666631801.7974 - val_loss: 31924953088.0000\n",
      "Epoch 71/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 34127187507.8767 - val_loss: 31896481792.0000\n",
      "Epoch 72/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 32228134718.0264 - val_loss: 31880103936.0000\n",
      "Epoch 73/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 31527698276.3700 - val_loss: 31839434752.0000\n",
      "Epoch 74/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 33327267483.6300 - val_loss: 31815761920.0000\n",
      "Epoch 75/75\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 31872115527.0485 - val_loss: 31790422016.0000\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 128)               2304      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 10,625\n",
      "Trainable params: 10,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating a Neural Network Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# For a simple ANN Keras API do not require to provide the number of input features, start with hidden layer\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='Adam', loss='mse')\n",
    "\n",
    "model.fit(x=X_train,y=y_train,\n",
    "          validation_data=(X_test,y_test),\n",
    "          epochs=75)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 109965.91525962077\n",
      "MSE: 31790425092.56221\n",
      "RMSE: 178298.6962727496\n",
      "R2 Square 0.7682030639672996\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print_evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Activation, Input\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='Adam', loss='mse')\n",
    "\n",
    "model.fit(x=X_train,y=y_train,\n",
    "          validation_data=(X_test,y_test), epochs=10)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print_evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
